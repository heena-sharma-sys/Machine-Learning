{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center><u><h1>Recurrent Neural Network RNN</center></u></h1>"
      ],
      "metadata": {
        "id": "Bihxn9NhONXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recurrent Neural Network (RNN):<br>\n",
        "A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes form a directed or undirected graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior. Derived from feedforward neural networks, RNNs can use their internal state (memory) to process variable length sequences of inputs.This makes them applicable to tasks such as unsegmented, connected handwriting recognition or speech recognition.\n",
        "![](https://www.simplilearn.com/ice9/free_resources_article_thumb/Simple_Recurrent_Neural_Network.png)"
      ],
      "metadata": {
        "id": "0lyC6uxROYxk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The nodes in different layers of the neural network are compressed to form a single layer of recurrent neural networks. A, B, and C are the parameters of the network.\n",
        "\n",
        "![](https://www.simplilearn.com/ice9/free_resources_article_thumb/Network_framework.gif)"
      ],
      "metadata": {
        "id": "GoyAMrBZOxUV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, “x” is the input layer, “h” is the hidden layer, and “y” is the output layer. A, B, and C are the network parameters used to improve the output of the model. At any given time t, the current input is a combination of input at x(t) and x(t-1). The output at any given time is fetched back to the network to improve on the output.\n",
        "![](https://www.simplilearn.com/ice9/free_resources_article_thumb/Fully_connected_Recurrent_Neural_Network1.png)"
      ],
      "metadata": {
        "id": "kHTOplhgO9nz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why Recurrent Neural Networks?<br>\n",
        "RNN were created because there were a few issues in the feed-forward neural network:\n",
        "1. Cannot handle sequential data\n",
        "2. Considers only the current input\n",
        "3. Cannot memorize previous inputs\n",
        "\n",
        "An RNN can handle sequential data, accepting the current input data, and previously received inputs. RNNs can memorize previous inputs due to their internal memory."
      ],
      "metadata": {
        "id": "ZIiUy07KPSyd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How Does Recurrent Neural Networks Work?\n",
        "![](https://www.simplilearn.com/ice9/free_resources_article_thumb/Fully_connected_Recurrent_Neural_Network.gif)"
      ],
      "metadata": {
        "id": "dNx38gWCPq6V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The input layer ‘x’ takes in the input to the neural network and processes it and passes it onto the middle layer.<br>\n",
        "The Recurrent Neural Network will standardize the different activation functions and weights and biases so that each hidden layer has the same parameters. Then, instead of creating multiple hidden layers, it will create one and loop over it as many times as required. "
      ],
      "metadata": {
        "id": "zG13GiXxP7g7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You read more about RNN here:<br>\n",
        "https://www.tensorflow.org/guide/keras/rnn"
      ],
      "metadata": {
        "id": "F76XsCDNogEX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applications of Recurrent Neural Networks\n",
        "1. Prediction problems.\n",
        "2. Language Modelling and Generating Text.\n",
        "3. Machine Translation.\n",
        "4. Speech Recognition.\n",
        "5. Generating Image Descriptions.\n",
        "6. Video Tagging.\n",
        "7. Text Summarization."
      ],
      "metadata": {
        "id": "1FbWSC3HQD7J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Types of Recurrent Neural Networks\n",
        "1. One to One<br>\n",
        "This type of neural network is known as the Vanilla Neural Network. It's used for general machine learning problems, which has a single input and a single output.\n",
        "\n",
        "2. One to Many<br>\n",
        "This type of neural network has a single input and multiple outputs. An example of this is the image caption.<br>\n",
        "3. Many to One<br>\n",
        "This RNN takes a sequence of inputs and generates a single output. Sentiment analysis is a good example of this kind of network where a given sentence can be classified as expressing positive or negative sentiments.<br>\n",
        "4. Many to Many<br>\n",
        "This RNN takes a sequence of inputs and generates a sequence of outputs. Machine translation is one of the examples.<br>\n",
        "![](https://srdas.github.io/DLBook/DL_images/rnn2.png)"
      ],
      "metadata": {
        "id": "4vYEStHDQUK3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><u>RNN for MNIST digits classification</h2></u>\n",
        "<br>\n",
        "Let's now do some coding. We will be solving a problem which is classification of MNIST digits. The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems. The MNIST database contains 60,000 training images and 10,000 testing images. The goal of this project is to create a model that will be able to recognize and determine the handwritten digits from its image.\n",
        "\n",
        "![mnist](https://upload.wikimedia.org/wikipedia/commons/thumb/2/27/MnistExamples.png/320px-MnistExamples.png)\n",
        "\n",
        "<br>\n",
        "Let's begin by importing the required libraries.\n",
        "<br>\n",
        "\n",
        "\n",
        "1.   Numpy: to perform array and matrix operations\n",
        "2.   Sequential: The core idea of Sequential API is simply arranging the Keras layers in a sequential order.\n",
        "3.   Dense layer: In any neural network, a dense layer is a layer that is deeply connected with its preceding layer which means the neurons of the layer are connected to every neuron of its preceding layer.\n",
        "4.   Activation layer: An activation function in a neural network defines how the weighted sum of the input is transformed into an output from a node or nodes in a layer of the network.\n",
        "5.   SimpleRNN layer: Fully-connected RNN where the output is to be fed back to input.\n",
        "6.   to_categorical: converts a vector which has integers that represent different categories, into a numpy array (or) a matrix which has binary values and has columns equal to the number of categories in the data.\n",
        "7.   plot_model: used to plot a trained model.\n",
        "8.   mnist: will load the mnist dataset which is already available in tensorflow.\n"
      ],
      "metadata": {
        "id": "Fv1vqLVePpJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the above mentioned libraries\n",
        "import numpy as np \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, SimpleRNN\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "metadata": {
        "id": "LMWuAfyfRgep"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will load the data using the load_data method in the variables (x_train, y_train), (x_test, y_test)."
      ],
      "metadata": {
        "id": "D_GmVudMQbrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load mnist dataset \n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "nIdIszx5Lq4y"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will find out the number of labels in the dataset i.e how many prediction classes are present. For that, we apply the len() function by passing in it unique values using np.unique function from y_train(which contains the predictions of training dataset)."
      ],
      "metadata": {
        "id": "8TAuaE5jQwPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(X_train[2])\n",
        "plt.title(y_train[2])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "BH7OvgegKVBY",
        "outputId": "c41f7c46-b3b8-4fe8-8a6e-387417794b58"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the number of labels\n",
        "num_labels = len(np.unique(y_train))"
      ],
      "metadata": {
        "id": "fC_9S8jcL00c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we will convert the prediction datasets into matrices having binary values. We will use to_categorical function that converts a vector which has integers that represent different categories, into a numpy array (or) a matrix which has binary values and has columns equal to the number of categories in the data.\n",
        "\n",
        "![to_categorical.png](https://miro.medium.com/max/1400/1*yJ8em7E3SdRjrOdi82E_3Q.png)"
      ],
      "metadata": {
        "id": "VQf9WrSvRoKh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are going to store image into a image_size variable and normalizes the supplied array and reshapes it into the appropriate format.<br>\n",
        "After converting we will normalize all the images for further training.\n",
        "We will normalize all values between 0 and 1 and we will flatten the images into vectors.\n",
        "Normalization of images is very important step for getting proper output because if we not normalize the image it can affect the accuracy of our model. So normalization is a neccessary step for better accuracy."
      ],
      "metadata": {
        "id": "tisrza5RbExw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_train.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTRf1Tz9MymN",
        "outputId": "d9d9540a-4f0d-4881-c28f-68bc8f4782a9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), 28)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the prediction data\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "41i2kYKOL5pv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = X_train.shape[1]\n",
        "X_train = np.reshape(X_train, [-1, image_size, image_size])\n",
        "X_test = np.reshape(X_test, [-1, image_size, image_size])\n",
        "\n",
        "X_train = X_train.astype('float32') / 255 \n",
        "X_test = X_test.astype('float32') / 255 "
      ],
      "metadata": {
        "id": "WtOWFoQvL7lD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "id": "i8GfP67fNCmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we set some of the parameter values which will be passed while training. <br>\n",
        "\n",
        "1.   input_shape: specifies the shape of the input, set to same as the image size\n",
        "2.   batch_size: The batch size defines the number of samples that will be propagated through the network. Here it is set to 128.\n",
        "3.   units: defines the size of the output from the dense layer. Here it is set to 256.\n",
        "4.   dropout: drops out certain neurons or layers for overcoming overfitting. Here the dropout rate is set to 0.2 i.e. 20% neurons are dropped out.\n",
        "\n"
      ],
      "metadata": {
        "id": "3AX5QWiOTcZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# network parameters\n",
        "input_shape = (image_size, image_size) \n",
        "batch_size = 128\n",
        "units = 256\n",
        "dropout = 0.2"
      ],
      "metadata": {
        "id": "umVc8NvIL96Y"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we create the model. The model will be a sequential model having 3 layers. First is the simple RNN layer, then the dense layer and finally the Activation layer. softmax is used as the activation function as it is multi-class classification problem. "
      ],
      "metadata": {
        "id": "lgqLBFYTV05g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model is RNN with 256 units, input is 28-dim vector 28 timesteps\n",
        "# initialize the sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# add the simpleRNN layer passing the above mentioned parameters\n",
        "model.add(SimpleRNN(units = units, dropout = dropout, input_shape = input_shape))\n",
        "# add the dense layer by passing the num_labels parameter\n",
        "model.add(Dense(num_labels))\n",
        "# add the activation layer\n",
        "model.add(Activation('softmax'))\n",
        "# check the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VL7_F-3uMEuf",
        "outputId": "4fef1040-3b01-4758-9e15-bb841ca15f74"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 256)               72960     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                2570      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 75,530\n",
            "Trainable params: 75,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we compile the model using the compile() method by paasing the parameters like loss, optimizer and metrics.<br>\n",
        "\n",
        "\n",
        "1.   loss:specifies the method to calculate the loss. Here it is categorical crossentropy as it is a classification problem. <br>\n",
        "Refer: https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/categorical-crossentropy\n",
        "2.   optimizer: Optimizers are algorithms or methods used to change the attributes of your neural network such as weights and learning rate in order to reduce the losses. Here we use sgd(stochastic gradient descent).<br>\n",
        " Refer: https://towardsdatascience.com/deep-learning-optimizers-436171c9e23f\n",
        "3.   metrics: A metric is a function that is used to judge the performance of your model. Here it is accuracy metric. RNN for MNIST digits classification\n",
        "<br>Refer: https://blog.paperspace.com/deep-learning-metrics-precision-recall-accuracy/\n",
        "\n",
        "<br>\n",
        "We also fit the model by passing the training data, epochs and batchszie.\n",
        "\n"
      ],
      "metadata": {
        "id": "6UYKzcI6X9fu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model by passing above mentioned parameters\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "# fit the model, set 20 epochs and batch size\n",
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=4) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Hz0sU2GMIws",
        "outputId": "4896e567-b8c5-48e4-d1ed-dc692967e41a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "469/469 [==============================] - 18s 36ms/step - loss: 0.7620 - accuracy: 0.7849\n",
            "Epoch 2/4\n",
            "469/469 [==============================] - 17s 36ms/step - loss: 0.3149 - accuracy: 0.9079\n",
            "Epoch 3/4\n",
            "469/469 [==============================] - 17s 36ms/step - loss: 0.2334 - accuracy: 0.9309\n",
            "Epoch 4/4\n",
            "469/469 [==============================] - 17s 36ms/step - loss: 0.1930 - accuracy: 0.9419\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7facfcfd1990>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model has now been trained. Lets check how well it has performed. We use the evaluate method by passing the test data and batch size.\n",
        "<br><br>By setting verbose 0, 1 or 2 you just say how do you want to 'see' the training progress for each epoch.\n",
        "\n",
        "verbose=0 will show you nothing (silent)\n",
        "\n",
        "verbose=1 will show you an animated progress bar like this:\n",
        "\n",
        "![dash.png](https://i.stack.imgur.com/s43II.png)\n",
        "\n",
        "verbose=2 will just mention the number of epoch like this:<br>\n",
        "![epoch.png](https://i.stack.imgur.com/gxbMD.png)"
      ],
      "metadata": {
        "id": "EqjJVcZoZqxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating our model\n",
        "_, acc = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)\n",
        "#accuracy of our model\n",
        "print(acc*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftxpc7DiMOmW",
        "outputId": "83ff9c72-6018-4847-c678-4cce9f65cfdc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95.77999711036682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "95% is the accuracy of our model."
      ],
      "metadata": {
        "id": "VF_dI-_Yu1Wd"
      }
    }
  ]
}