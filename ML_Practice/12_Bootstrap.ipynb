{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Bootstrap_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sNKZq4XrXQh"
      },
      "source": [
        "# <font color='red'><b>Bootstrap assignment</b> </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAHap1Z3FZC-"
      },
      "source": [
        "<b>There will be some functions that start with the word \"grader\" ex: grader_sampples(), grader_30().. etc, you should not change those function definition.\n",
        "\n",
        "Every Grader function has to return True.</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuxBq_bvrwh2"
      },
      "source": [
        "<font color='blue'> <b>Importing packages</b> </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6ag91ijrQOs"
      },
      "source": [
        "import numpy as np # importing numpy for numerical computation\n",
        "from sklearn.datasets import load_boston # here we are using sklearn's boston dataset\n",
        "from sklearn.metrics import mean_squared_error # importing mean_squared_error metric"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td-o9CremKnw"
      },
      "source": [
        "boston = load_boston()\n",
        "x=boston.data #independent variables\n",
        "y=boston.target #target variable"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEa_HqRZloH4"
      },
      "source": [
        "## <font color='red'><b>Task 1</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ5q8IxHNRk3"
      },
      "source": [
        "<font color='red'> <b>Step - 1</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJCFCaOzl7Mr"
      },
      "source": [
        "*  <font color='blue'><b>Creating samples</b></font><br>\n",
        "    <b> Randomly create 30 samples from the whole boston data points</b>\n",
        "    *  Creating each sample: Consider any random 303(60% of 506) data points from whole data set and then replicate any 203 points from the sampled points\n",
        "    \n",
        "     For better understanding of this procedure lets check this examples, assume we have 10 data points [1,2,3,4,5,6,7,8,9,10], first we take 6 data points randomly , consider we have selected [4, 5, 7, 8, 9, 3] now we will replicate 4 points from [4, 5, 7, 8, 9, 3], consder they are [5, 8, 3,7] so our final sample will be [4, 5, 7, 8, 9, 3, 5, 8, 3,7]\n",
        "* <font color='blue'><b> Create 30 samples </b></font>\n",
        "    *  Note that as a part of the Bagging when you are taking the random samples <b>make sure each of the sample will have different set of columns</b><br>\n",
        "Ex: Assume we have 10 columns[1 ,2 ,3 ,4 ,5 ,6 ,7 ,8 ,9 ,10] for the first sample we will select [3, 4, 5, 9, 1, 2] and for the second sample  [7, 9, 1, 4, 5, 6, 2] and so on...\n",
        "Make sure each sample will have atleast 3 feautres/columns/attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUqFEBSvNjCa"
      },
      "source": [
        "<font color='red'><b>Step - 2 </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqi9AhCYNq3Z"
      },
      "source": [
        "<font color='blue'><b>Building High Variance Models on each of the sample and finding train MSE value</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lLBnZHXOFln"
      },
      "source": [
        "*  Build a regression trees on each of 30 samples.\n",
        "*  Computed the predicted values of each data point(506 data points) in your corpus.\n",
        "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{30}\\sum_{k=1}^{30}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$\n",
        "*  Now calculate the $MSE =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kls23JLnSN23"
      },
      "source": [
        "<font color='red'> <b>Step - 3 </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz2GchkGSWnh"
      },
      "source": [
        "*  <font color='blue'><b>Calculating the OOB score </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGHkVV2kSibm"
      },
      "source": [
        "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{k}\\sum_{\\text{k= model which was buit on samples not included } x^{i}}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.\n",
        "*  Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK860ocxTyoz"
      },
      "source": [
        "# <font color='red'><b>Task 2</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dme-N6TUCrY"
      },
      "source": [
        "*  <font color='blue'><b>Computing CI of OOB Score and Train MSE</b></font>\n",
        "  *   Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score </li>\n",
        "<li> After this we will have 35 Train MSE values and 35 OOB scores </li>\n",
        "<li> using these 35 values (assume like a sample) find the confidence intravels of MSE and OOB Score </li>\n",
        "<li> you need to report CI of MSE and CI of OOB Score </li>\n",
        "<li> Note: Refer the Central_Limit_theorem.ipynb to check how to find the confidence intravel</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6UcH1x9Uwrj"
      },
      "source": [
        "# <font color='red'><b>Task 3</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOC_AgsLU7OH"
      },
      "source": [
        "*  <font color='blue'><b>Given a single query point predict the price of house.</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYs5jSFdVILe"
      },
      "source": [
        "Consider xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] \n",
        "Predict the house price for this point as mentioned in the step 2 of Task 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2fHTdS_zpgG"
      },
      "source": [
        "# <font color='blue'> <b>Task - 1</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0yGBuryOwHz"
      },
      "source": [
        "<font color='blue'><b>Step - 1</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJXX8vf3z073"
      },
      "source": [
        "*  <font color='blue'> <b>Creating samples</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSVaWG1F4uCZ"
      },
      "source": [
        "<font color='Orange'><b>Algorithm</b></font>\n",
        "\n",
        "![alt text](https://i.imgur.com/BTVYXQ1.jpg/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_oWoN97BhDY"
      },
      "source": [
        "*  <font color='blue'><b> Write code for generating samples</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I39OpgEMkliD"
      },
      "source": [
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCIYs6Ww0RiU"
      },
      "source": [
        "def generating_samples(input_data, target_data):\n",
        "  '''In this function, we will write code for generating 30 samples '''\n",
        "  # you can use random.choice to generate random indices without replacement\n",
        "  # Please have a look at this link https://docs.scipy.org/doc/numpy-1.16.0/reference/generated/numpy.random.choice.html for details\n",
        "  \n",
        "  selected_rows = np.random.choice(len(input_data), 303, replace = False)\n",
        "  selected_rows = np.sort(selected_rows)\n",
        "\n",
        "\n",
        "  replaced_rows = np.random.choice(selected_rows, 203, replace = False)\n",
        "  replaced_rows = np.sort(replaced_rows)\n",
        "\n",
        "  selected_columns = np.sort(np.random.choice(input_data.shape[1], size=random.randint(3, input_data.shape[1]), replace =False))\n",
        "  \n",
        "  sample_data = input_data[selected_rows[:,None],selected_columns]\n",
        "  target_sameple_data = target_data[selected_rows]\n",
        "\n",
        "  replicating_data = input_data[replaced_rows[:,None],selected_columns]\n",
        "  target_replicating_data = target_data[replaced_rows]\n",
        "\n",
        "  final_sample_data = np.vstack((sample_data, replicating_data))\n",
        "  final_target_data = np.vstack((target_sameple_data.reshape(-1,1),target_replicating_data.reshape(-1,1)))\n",
        "  return final_sample_data, final_target_data, selected_rows, selected_columns\n",
        "  "
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4LSsmn4Jn2_"
      },
      "source": [
        "*  <font color='blue'> <b>Create 30 samples </b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ec7MN6sL2BZ"
      },
      "source": [
        "![alt text](https://i.imgur.com/p8eZaWL.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tiF38qy5gZL"
      },
      "source": [
        "# Use generating_samples function to create 30 samples\n",
        "# store these created samples in a list\n",
        "list_input_data =[]\n",
        "list_output_data =[]\n",
        "list_selected_row= []\n",
        "list_selected_columns=[]\n",
        "for i in range(0,30):\n",
        "  final_sample_data, final_target_data, selected_rows, selected_columns = generating_samples(x,y)\n",
        "  #grader_samples(final_sample_data , final_target_data,selected_rows,selected_columns)\n",
        "  # Append the info in the respective list.\n",
        "  list_input_data.append(final_sample_data)\n",
        "  list_output_data.append(final_target_data)\n",
        "  list_selected_row.append(selected_rows)\n",
        "  list_selected_columns.append(selected_columns)"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MivEQFlm7iOg"
      },
      "source": [
        "<font color='cyan'> <b> Grader function - 1 </b> </fongt>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax9opVBJEAMW"
      },
      "source": [
        "def grader_samples(a,b,c,d):\n",
        " length = (len(a)==506 and len(b)==506)\n",
        " sampled = (len(a)- len(set([str(i) for i in a]))==203)\n",
        " rows_length = (len(c)==303)\n",
        " column_length= (len(d)>=3)\n",
        " #print (length, sampled, rows_length, column_length)\n",
        " assert(length and sampled and rows_length and column_length)\n",
        "\n",
        " return True"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X96XmJUI1iyh",
        "outputId": "91020270-ccf6-400d-d24f-ac207b0dbdf2"
      },
      "source": [
        "a,b,c,d = generating_samples(x, y) \n",
        "grader_samples(a,b,c,d)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXUz9VFiMQkh"
      },
      "source": [
        "<font color='cyan'> <b>Grader function - 2 </b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF6bkapc62wb",
        "outputId": "97abe97a-762e-40d2-a1de-9d9270dcf067"
      },
      "source": [
        "def grader_30(a):\n",
        "  assert(len(a)==30 and len(a[0])==506) \n",
        "  return True\n",
        "grader_30(list_input_data)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Pv-mkZkO6dh"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whaHCPB0O8qF"
      },
      "source": [
        "<font color='red'><b>Step - 2 </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBy4zXSWPtU8"
      },
      "source": [
        "<font color='orange'><b>Flowchart for building tree</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xvH06HPQBdP"
      },
      "source": [
        "![alt text](https://i.imgur.com/pcXfSmp.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRwPO_uHQjul"
      },
      "source": [
        "*  <font color='blue'><b> Write code for building regression trees</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWQp6tRwMthq"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor \n",
        "list_of_all_models = []\n",
        "for i in range(0, 30):\n",
        "  input_data = list_input_data[i]\n",
        "  target_data = list_output_data[i]\n",
        "  classifier = DecisionTreeRegressor(max_depth=None,min_samples_split=2) \n",
        "  classifier.fit(input_data, target_data) \n",
        "  list_of_all_models.append(classifier)"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21j8BKfAQ1U8"
      },
      "source": [
        "<font color='orange'><b>Flowchart for calculating MSE </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q0mTBD2RBx_"
      },
      "source": [
        "![alt text](https://i.imgur.com/sPEE618.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e-UamlHRjPy"
      },
      "source": [
        "After getting predicted_y for each data point, we can use sklearns mean_squared_error to calculate the MSE between predicted_y and actual_y."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnIMT7_oR312"
      },
      "source": [
        "*  <font color='blue'><b> Write code for calculating MSE</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWhcvMRWRA9b"
      },
      "source": [
        "import statistics\n",
        "\n",
        "list_predict = []\n",
        "for i in range(0,30):\n",
        "  pred_y = list_of_all_models[i].predict(x[:,list_selected_columns[i]]) \n",
        "  list_predict.append(pred_y)\n",
        "\n",
        "# Calculating median for each data point from predicted y of each model\n",
        "final_y_predict = [] \n",
        "\n",
        "for i in range(0, 506):\n",
        "  med_y = []\n",
        "  for j in range(0, 30):\n",
        "    med_y.append(list_predict[j][i]) \n",
        "  med = statistics.median(med_y) \n",
        "  final_y_predict.append(med)"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFqTwpL48mbO",
        "outputId": "8aa57582-49a8-4fc6-f13b-64bab1104527"
      },
      "source": [
        "# Calculating MSE :\n",
        "from sklearn.metrics import mean_squared_error \n",
        "mse = mean_squared_error(y, final_y_predict) \n",
        "print(\"=\" * 30)\n",
        "print(\"MSE on train data set : \" , mse) \n",
        "print(\"=\" * 30)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==============================\n",
            "MSE on train data set :  0.06123023715415015\n",
            "==============================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuclPDMnSz8F"
      },
      "source": [
        "<font color='blue'><b>Step - 3 </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESb9FSIDTM5V"
      },
      "source": [
        "<font color='orange'><b>Flowchart for calculating OOB score</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HB-d6NMETbd9"
      },
      "source": [
        "![alt text](https://i.imgur.com/95S5Mtm.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4MadCEothQf"
      },
      "source": [
        "*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{k}\\sum_{\\text{k= model which was buit on samples not included } x^{i}}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.\n",
        "*  Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBqcS03pUYSZ"
      },
      "source": [
        "*  <font color='blue'><b> Write code for calculating OOB score </b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fog_6DNdS-h_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1acd5a89-d676-4fb7-cf52-2f72abf37061"
      },
      "source": [
        "oob_y_predict = []\n",
        "y_sample_predict = []\n",
        "# iterating through each data point. \n",
        "for i in range (0,506):\n",
        "  data = x[i]\n",
        "  for j in range(0,30):\n",
        "    if i not in list_selected_row[j]:\n",
        "      pred_y = list_of_all_models[j].predict(data[list_selected_columns[j]].reshape(1,-1)) \n",
        "      y_sample_predict.append(pred_y[0])\n",
        "  y_sample_predict_oobs = statistics.median(y_sample_predict) \n",
        "  y_sample_predict.clear() \n",
        "  oob_y_predict.append(y_sample_predict_oobs)\n",
        "\n",
        "#print((oob_y_predict))\n",
        "#Calculate OObs score now :\n",
        "total_error = 0\n",
        "for i in range(0, 506):\n",
        "  error = y[i] - oob_y_predict[i] \n",
        "  error = error * error #Square error :\n",
        "  total_error = total_error + error \n",
        "oobs_score = total_error/506 \n",
        "print(\"=\" * 30)\n",
        "print(\"OOBS Score : \" , oobs_score) \n",
        "print(\"=\" * 30)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==============================\n",
            "OOBS Score :  14.860715612648221\n",
            "==============================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbuiwX3OUjUI"
      },
      "source": [
        "# <font color='blue'><b>Task 2</b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceW5-D88Uswi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a00c60c-e436-4649-902c-27cead2656cc"
      },
      "source": [
        "# repeat Task 1 35 times :\n",
        "train_mse_list = [] \n",
        "oobs_score_list = []\n",
        "for iteration in range (1 , 36):\n",
        "  list_input_data =[] \n",
        "  list_output_data =[] \n",
        "  list_selected_row= [] \n",
        "  list_selected_columns=[] \n",
        "  list_of_all_models = [] \n",
        "  list_predict = [] \n",
        "  oob_y_predict = [] \n",
        "  y_sample_predict = []\n",
        "  \n",
        "  for i in range(0,30):\n",
        "    final_sample_data, final_target_data, selected_rows, selected_columns = generating_samples(x,y)\n",
        "    # Append the info in the respective list.\n",
        "    list_input_data.append(final_sample_data) \n",
        "    list_output_data.append(final_target_data) \n",
        "    list_selected_row.append(selected_rows) \n",
        "    list_selected_columns.append(selected_columns)\n",
        "\n",
        "  #Write code for building regression trees\n",
        "  for i in range(0, 30):\n",
        "    input_data = list_input_data[i]\n",
        "    target_data = list_output_data[i]\n",
        "    classifier = DecisionTreeRegressor(max_depth=None,min_samples_split=2) \n",
        "    classifier.fit(input_data,target_data) \n",
        "    list_of_all_models.append(classifier)\n",
        "  \n",
        "  # write code for Calculating MSE :\n",
        "  for i in range(0,30):\n",
        "    pred_y = list_of_all_models[i].predict(x[:,list_selected_columns[i]]) \n",
        "    list_predict.append(pred_y)\n",
        "    # Calculating median for each data point from predicted y of each model.\n",
        "  final_y_predict = [] \n",
        "  for i in range(0 , 506):\n",
        "    med_y = []\n",
        "    for j in range(0 , 30):\n",
        "      med_y.append(list_predict[j][i]) \n",
        "    med = statistics.median(med_y) \n",
        "    final_y_predict.append(med)\n",
        "\n",
        "  # Calculating MSE :\n",
        "  mse = mean_squared_error(y, final_y_predict) \n",
        "  print(\"=\" * 30)\n",
        "  print(\"Iteration = : \" , iteration) \n",
        "  print(\"MSE on train data \" , mse) \n",
        "  train_mse_list.append(mse)\n",
        "  # Calculating OOBS score\n",
        "  # iterating through each data point. \n",
        "  for i in range (0,506):\n",
        "    data = x[i]\n",
        "    for j in range(0,30):\n",
        "      if i not in list_selected_row[j]:\n",
        "        pred_y = list_of_all_models[j].predict(data[list_selected_columns[j]].reshape(1,-1)) \n",
        "        y_sample_predict.append(pred_y[0])\n",
        "    y_sample_predict_oobs = statistics.median(y_sample_predict) \n",
        "    y_sample_predict.clear() \n",
        "    oob_y_predict.append(y_sample_predict_oobs)\n",
        "\n",
        "  #Calculate OObs score now :\n",
        "  total_error = 0\n",
        "  for i in range(0,506):\n",
        "    error = y[i] - oob_y_predict[i] #Square error :\n",
        "    error = error * error \n",
        "    total_error += error\n",
        "  oobs_score = total_error/506 \n",
        "  print(\"OOBS Score : \" , oobs_score) \n",
        "  print(\"=\" * 30) \n",
        "  oobs_score_list.append(oobs_score)"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==============================\n",
            "Iteration = :  1\n",
            "MSE on train data  0.026442687747035606\n",
            "OOBS Score :  11.246935055972319\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  2\n",
            "MSE on train data  0.26442687747035565\n",
            "OOBS Score :  13.73833498023715\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  3\n",
            "MSE on train data  0.1078557312252965\n",
            "OOBS Score :  12.350770750988143\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  4\n",
            "MSE on train data  0.020286561264822124\n",
            "OOBS Score :  18.15286190711461\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  5\n",
            "MSE on train data  0.008922924901185781\n",
            "OOBS Score :  13.91498023715414\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  6\n",
            "MSE on train data  0.03548812212632089\n",
            "OOBS Score :  18.222345231029685\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  7\n",
            "MSE on train data  0.02956027667984188\n",
            "OOBS Score :  12.81495553359683\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  8\n",
            "MSE on train data  0.0753471219807576\n",
            "OOBS Score :  12.660466036279141\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  9\n",
            "MSE on train data  0.06647233201581033\n",
            "OOBS Score :  15.012462597032545\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  10\n",
            "MSE on train data  0.10600029386112711\n",
            "OOBS Score :  11.484972135454287\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  11\n",
            "MSE on train data  0.06942826704545457\n",
            "OOBS Score :  14.426508966746411\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  12\n",
            "MSE on train data  0.1593972332015811\n",
            "OOBS Score :  16.883961379097094\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  13\n",
            "MSE on train data  0.02001482213438734\n",
            "OOBS Score :  13.755258167578615\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  14\n",
            "MSE on train data  0.19947472184222984\n",
            "OOBS Score :  14.79439018104647\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  15\n",
            "MSE on train data  0.09996496135875665\n",
            "OOBS Score :  15.696652499850611\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  16\n",
            "MSE on train data  0.1985129040160731\n",
            "OOBS Score :  15.255477704411375\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  17\n",
            "MSE on train data  0.06558684672815097\n",
            "OOBS Score :  15.843335651436242\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  18\n",
            "MSE on train data  0.0696257411067194\n",
            "OOBS Score :  13.573347194773818\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  19\n",
            "MSE on train data  0.06585474308300392\n",
            "OOBS Score :  12.965644685990327\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  20\n",
            "MSE on train data  0.2344144553093252\n",
            "OOBS Score :  14.719237355377253\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  21\n",
            "MSE on train data  0.036400966183574864\n",
            "OOBS Score :  15.549275674158613\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  22\n",
            "MSE on train data  0.04368083003952572\n",
            "OOBS Score :  12.955169219367583\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  23\n",
            "MSE on train data  0.12095553908651732\n",
            "OOBS Score :  15.689476154118573\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  24\n",
            "MSE on train data  0.025498076630727184\n",
            "OOBS Score :  13.978845048662876\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  25\n",
            "MSE on train data  0.06297430830039526\n",
            "OOBS Score :  13.688147233201576\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  26\n",
            "MSE on train data  0.057588932806324135\n",
            "OOBS Score :  14.646519474112514\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  27\n",
            "MSE on train data  0.11796048666007895\n",
            "OOBS Score :  14.528702565902709\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  28\n",
            "MSE on train data  0.1276784145805885\n",
            "OOBS Score :  10.740686896135262\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  29\n",
            "MSE on train data  0.011413043478260857\n",
            "OOBS Score :  13.841020471357599\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  30\n",
            "MSE on train data  0.04966403162055339\n",
            "OOBS Score :  13.043169416996047\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  31\n",
            "MSE on train data  0.0885365393061045\n",
            "OOBS Score :  12.970766020446739\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  32\n",
            "MSE on train data  0.027707509881422898\n",
            "OOBS Score :  14.344813610135162\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  33\n",
            "MSE on train data  0.048103315766359345\n",
            "OOBS Score :  14.544954185275262\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  34\n",
            "MSE on train data  0.02906140206411946\n",
            "OOBS Score :  12.964700160573123\n",
            "==============================\n",
            "==============================\n",
            "Iteration = :  35\n",
            "MSE on train data  0.2214495443566097\n",
            "OOBS Score :  15.409598986043923\n",
            "==============================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU1SZfogB7lA"
      },
      "source": [
        "Caclulate COnfidence Interval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEUZP_1zB5Z8",
        "outputId": "3cad8d93-3c02-4ce7-dd28-2f2a93ae859a"
      },
      "source": [
        "#Converting list to array\n",
        "import math\n",
        "train_mse = np.asarray(train_mse_list) \n",
        "oobs_score = np.asarray(oobs_score_list)\n",
        "\n",
        "# Compute mean\n",
        "mean_mse = np.mean(train_mse) \n",
        "mean_oobs = np.mean(oobs_score)\n",
        "\n",
        "#Compute STD:\n",
        "std_mse = np.std(train_mse) \n",
        "std_oobs = np.std(oobs_score)\n",
        "\n",
        "#Compute Standard error:\n",
        "sqrt_n = math.sqrt(30) \n",
        "standard_error_mse = std_mse/sqrt_n \n",
        "standard_error_obs = std_oobs/sqrt_n\n",
        "\n",
        "#CI for MSE:\n",
        "lower_limit_mse = mean_mse - 2 * (standard_error_mse) \n",
        "upper_limit_mse = mean_mse + 2 * (standard_error_mse)\n",
        "print(\"=\" * 30)\n",
        "print(\"CI for MSE :\" , lower_limit_mse , \",\" , upper_limit_mse)\n",
        "\n",
        "#CI for MSE :\n",
        "lower_limit_oobs = mean_oobs - 2 * (standard_error_obs) \n",
        "upper_limit_oobs = mean_oobs + 2 * (standard_error_obs)\n",
        "print(\"CI for oob :\" , lower_limit_oobs , \",\" , upper_limit_oobs) \n",
        "print(\"=\" * 30)"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==============================\n",
            "CI for MSE : 0.06093333519577696 , 0.11002383999618859\n",
            "CI for oob : 13.575609080006858 , 14.790604826716264\n",
            "==============================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKTnJdiBVS_e"
      },
      "source": [
        "# <font color='blue'><b>Task 3</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXxrvZqHV1Fr"
      },
      "source": [
        "<font color='orange'><b>Flowchart for Task 3</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyjwEJ62V6a6"
      },
      "source": [
        "<b>Hint: </b> We created 30 models by using 30 samples in TASK-1. Here, we need send query point \"xq\"  to 30 models and perform the regression on the output generated by 30 models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0emSwLL7VurD"
      },
      "source": [
        "![alt text](https://i.imgur.com/Y5cNhQk.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29hjwKlWWDfo"
      },
      "source": [
        "*  <font color='blue'><b> Write code for TASK 3 </b></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j87ZN72R1rpe",
        "outputId": "91068d6d-7675-4d1f-bba7-4f91998a905e"
      },
      "source": [
        "xq = np.array([0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60])\n",
        "total_price = 0\n",
        "for j in range(0,30):\n",
        "  pred_y = list_of_all_models[j].predict(xq[list_selected_columns[j]].reshape(1,-1))\n",
        "  total_price += pred_y\n",
        "\n",
        "# Not predicted price for the query point will be average of all prices predicted.\n",
        "predicted_price = total_price/30\n",
        "print(\"=\" * 50)\n",
        "print(\"Predicted price for query point xq is :\" , predicted_price) \n",
        "print(\"=\" * 50)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Predicted price for query point xq is : [19.54333333]\n",
            "==================================================\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}